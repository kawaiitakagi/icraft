# TSN
![version](https://img.shields.io/badge/icraft_ver-3.7.1-gold?style=flat&logo=data:image/png;base64,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)  ![author](https://img.shields.io/badge/author-ylm-blue)<br>![metrics](https://img.shields.io/badge/metrics-OK-green?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADwAAAA8CAYAAAA6/NlyAAAAAXNSR0IArs4c6QAAAAlwSFlzAAAPYQAAD2EBqD+naQAABLZJREFUaEPtmmnIpWMYx39/+75lyy6ELGNohA8GIUvEB6RBtomYmhhDIlskkmUSWcLIyDKU9QOy88FSjCIylmSZsoxl7OPSf7pOPY7zvs8573Oa55x3nqveOr33fT/P/buv5f7f9zliGTMtY7w0wOPd442HGw+PsxVoQrrdoRGxOrBN4f8LJC0YVseXejgidgXeLQBeJ2lmAzwkK9B4uEMONyFdlsMRsTywPrAKsFDSj4MS8X0P6YjYCJgK7A2sCnwPvAA8IOm7usH7ChwRWwNP5DZm79oC+BV4EjhT0sI6ofsGHBGbA48Du40C9DRwvKSf6oLuC3BErAlcDpwNrJQw3wBfALtkLrcY7wBmSPq5Duh+Ae8P3AVslRBfA1cCLwJHARcAa2WbvTvD/SX9s7ShKwNHhHP1UuB8YDngb8BenClpUUpTA18IrJA5/TpwmqQPhxF4U+Clgt52KB8p6c0WTETY83cCB8CSWxYvihdhliR/7tkiwou3WJKLYtfWDw87ZB9J7/rFDwJTJC0uziIipgC3FELb+vxQSQ7/ri33+B2BycDcXg8y/QA24LGFGR8s6dl2gohYA3gUOCjbvCAO69nd0kbE2sAprvTAzsCNki7qdrz7VQLO1bawaBWkz4HtJP3VaRIR4eL2fKFtnqQJZROOCM/THr0W2AlYLcf8Buwj6Z2yZ7TaqwLvAbxVeNlsSSeP9vKIeAOYVOgzWdLLIyyQ89Q14hzgdMBn83bzTuDU+L0b6KrAnsj1hRcdJ+mhEuCTgLsLOX8PcGqn4hMRvni4DDgEWK8wpviKX4Bzc5v7T93oNI+qwI+5IueDvb9OkvRRCbAVmbV16xblE2BfSV92yHunypb5t316eYe2fq7Sr7mtm22uKrDDbU9gIrAucImkH0qArcpmAa3Qt+KaJuneknEOb4e+DyW2RYAXy0ruT+Bi4CZJ/jyiVQLuJmc6eM3vPCHFycrZPicr9h8jPTMivLjO/02yj/f5w1PIuPLb8zeUHU6WOrAnGxG7A85de8f2nrcbSW+PAnwE4ChYJ/vclprcnu7a6gL2nmwRYjFiOeoKa319eyflFRHuc1X2WTFDeLqjpF3glJHXApxePibD2mLC9ipwtKRvO6TBZnk4aYmW+RkRr5QBtrfXCezi5SJUPD+fKOm+4iRTdByWWnzjbPO52irNur0nqw04vWxJej/gOzDbp8CBklx9l1ietq4Bzkpl6PD30fPqsRwv6wb20XJuVtsWo/X2VEmWrAbeLw8kG2aHr6zHJb3fk2uzc63ACWRt/Exhu/HWdGsqLIew78K2LcDdDEwfi3f9jEEA9pXQtAxT33IuWYcM7w0A53rLHPITq1z71g6cXjbYFdbUhTux9oj9LBXZU2MJ5daYgQBO6C3ymuiMvAoqcn2cIf5wmXQsW4yBAU5oC5K9gPPyCGld/lyKlA9GOmeXQRbbBwq4l4mPtW8D3L5yzRfi0PwCYKz5VMe4JoebHP7/r3h8teKvVgbRXF9G/UnVWEJ6EEFbc5ogad5oE2yAu8jhce9hX6X6EnwYbL6/k64U0sNA2cscS3O4l4cNQ98GeBi8VGWOjYerrN4wjG08PAxeqjLHfwG92SNbyY+y8QAAAABJRU5ErkJggg==)  ![speed](https://img.shields.io/badge/speed-OK-green?style=flat&logo=fastapi)<br>![FPGA_ops](https://img.shields.io/badge/FPGA_ops-ImageMake%20%7C%20WarpAffine-lightgreen?style=flat)<br><a href="../../index.md#cv-ar" target="_blank"><img alt="模型清单" src="https://img.shields.io/badge/cv--ar-模型清单-cornflowerblue?logo=quicklook"></a><br>![OS](https://img.shields.io/badge/OS-Windows%20%7C%20Ubuntu-green)

# 下载

✨ 一键下载开发流程中所需的各种文件，包括编译使用的量化校准集、运行时工程的依赖库，以及输入输出文件。

💡 推荐使用linux版下载脚本，其wget包含断网自动重连功能，不会出现下载文件遗漏情况。

## windows
📌 第一次使用，请在C盘根目录下新建`icraft_auth.txt`，保存下载站账号密码，以换行符分隔

需要事先下载windows版本wget：

（若点击以下链接后未直接下载，请选择 ***1.20.3*** 版本下的对应系统链接进行下载）

[x86系统wget下载](https://eternallybored.org/misc/wget/1.20.3/32/wget.exe)		[x64系统wget下载](https://eternallybored.org/misc/wget/1.20.3/64/wget.exe)

使用时需要将wget.exe的路径作为命令行参数传入，注意不是exe的父文件夹目录，而是包含wget.exe的完整绝对路径：

不下载Deps：`./download.ps1 "PATH_TO_WGET_EXE"`

如果您是第一次使用我们的模型库，请下载包括工程依赖库的所有文件：`./download.ps1 "PATH_TO_WGET_EXE" -d`

💡 下载过程中可能因网络问题出现中断情况，需 **自行重新运行** 下载脚本。

## linux

📌 第一次使用，请在/usr根目录下新建`icraft_auth.txt`，保存下载站账号密码，以换行符分隔

为确保文件格式正确，请在运行脚本前安装格式转换工具`dos2unix`，并执行格式转换命令：
```shell
sudo apt-get install dos2unix
dos2unix /usr/icraft_auth.txt
dos2unix ./download.sh
```

如果您是第一次使用我们的模型库，请下载包括工程依赖库的所有文件：`./download.sh -d`

如果之前已经在使用别的模型时下载过Deps依赖库，可以直接将其中的thirdparty部分复制到路径`3_deploy/Deps`，只需下载量化校准集和输入输出文件即可：`./download.sh`


🌟 Tips：

- 若想要直接获取原始weights和导出保存的模型，可分别前往 [weights](https://download.fdwxhb.com/data/04_FMSH-100AI/100AI/04_modelzoo/modelzoo_pub/weights/) 和 [fmodels](https://download.fdwxhb.com/data/04_FMSH-100AI/100AI/04_modelzoo/modelzoo_pub/compile/fmodels/) 网页上根据框架及模型名寻找并下载。


# 0. 文件结构说明

AI部署模型需要以下几部分文件

- 0_TSN    >模型原始工程，需要自行下载
- weights              >存放原始权重，需要自行下载
- 1_scripts            >若干脚本，用于保存Icraft编译器需要的模型、编译后仿真等功能
- 2_compile          >Icraft编译器编译模型时所需要的文件
- 3_deploy            >将Icraft编译器编译出的模型部署到硬件时需要的c++工程

# 1. python工程准备

## 1. **模型来源：**

- code：https://github.com/open-mmlab/mmaction2.git
- branch：main
- commit_id：4d6c934
- weights：https://download.openmmlab.com/mmaction/v1.0/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20220906-cd10898e.pth

## 2. **保存模型**

**目的：将模型保存成可以被Icraft编译器编译的形态**

1）根据模型来源中的地址：https://download.openmmlab.com/mmaction/v1.0/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20220906-cd10898e.pth ，下载原始weights，存放于 `/weights`文件夹中

<div style="background-color: #FFFFCC; color: #000000; padding: 10px; border-left: 5px solid #FFA500;">
注意：

* 有时开源的weights url可能会变更。如果上述weights url失效，请根据原工程相应的branch以及commit版本寻找正确的下载链接
* 若上述weights url永久失效，请联系本模型库相关人员获取权限下载
</div>
2）根据模型来源中的地址，下载指定commit id版本的源代码，文件夹名称要设置为：0_TSN

```shell
# 在此模型根目录
mkdir 0_TSN
git clone -b main https://github.com/open-mmlab/mmaction2.git 0_TSN
cd 0_TSN
git checkout 4d6c934
```

3）mmaction2环境配置，可参考官方文档:[安装 — MMAction2 1.2.0 文档](https://mmaction2.readthedocs.io/zh-cn/latest/get_started/installation.html)。由于mmaction中使用到了mmcv1.x版本，因此必须在GPU环境下进行配置。参考配置：python==3.8.0、torch1.9.0+cu111、torchvision-0.10.0、mmcv==1.21.0、mmengine等

4）安装好环境后，将1_scripts中的文件手动复制到0_TSN中，执行保存模型脚本1_save.py。

注意：如需导出其它segment大小的模型，需重新设置“SEGMENTS=n”字段，表示将视频总共视频切分为n段

```shell
# 在此模型根目录
cd 1_scripts
python 1_save.py
```

**1_scripts提供脚本说明：**

- **环境要求：**Icraft编译器对**导出框架模型时**使用的**框架版本**有要求。即以下脚本中所有导出模型的脚本 `1_save.py  `，必须在要求的框架版本下执行，其他脚本不限制。要求的版本：
  - **pytorch**：支持pytorch1.9.0、pytorch2.0.1两个版本的原生网络模型文件（.pt格式），以及pytorch框架保存为onnx（opset=17）格式的模型文件（.onnx格式）
  - **paddle**：仅支持PaddlePaddle框架保存为onnx（opset=11）格式的模型文件（.onnx格式），不支持框架原生网络模型文件
  - **darknet**：支持Darknet框架原生网络模型[GitHub - pjreddie/darknet: Convolutional Neural Networks](https://github.com/pjreddie/darknet)
- 0_infer.py                      	    >可以推理一段视频并得到最终结果，模型原始权重会从 `/weights	`中寻找，需要您预先下载
- 1_save.py                              >保存模型，保存好的用于Icraft编译器的模型，会存放在 `/2_compile/fmodel`

  <div style="background-color: #FFFFCC; color: #000000; padding: 10px; border-left: 5px solid #FFA500;">
  保存模型时的修改点：<br>
    1.将模型分为两部分，一部分TSN-net1用于每帧都进行特征提取，另一部分TSN-net2则用于将segment帧TSN-net1的输出融合到一起，产生段共识，即得到动作类别得分。为方便量化部署，将TSN-ne1和TSN-net2两部分使用expand(SEGMENTS, -1)拼接到一起,导出一个TSN网络，编译完成后，再在部署阶段将其拆分为两部分。<br>
      2.将AvgConsensus()等效替换为mean(dim=1,keepdim=True)，即将TSN-net2的输入[1,25,2048]在dim=1维度上求均值。<br>
      3.简化了源码求动作类别得分的代码。<br>
  </div>

  

# 2.使用Icraft编译器编译模型

目的： 使用[Icraft编译器](https://gitee.com/mxh-spiger/icraft-introduction.git)将上一步保存好的**框架模型**转化为**硬件可部署模型**

- **1）相关命名说明：**

  1）**fmodel**：frame model         			>用于Icraft编译器的框架模型

  2）**imodel**：icraft model				   >用Icraft编译器编译出的模型

  3）**qtset**：Quantitative Calibration Set	  >Icraft编译器所需的量化校准集
- **2）确认已安装正确的icraft版本**

  检查方法：打开cmd运行：`icraft --version`

  若已正常安装则会显示当前icraft版本，例如：

  ```
  Icraft 版本:
   * 3.7.1
  
  CLI 版本:
  3.7.0.0-a90988f(2412231401)
  ```
- 3）**执行编译：**

     
**在 `/2_compile`目录下执行编译：**
  
     ```shell
      icraft compile config/TSN_25frames_psin_8.toml
     ```
  
     如果过程顺利，将得到 icraft model（以 `.json` （graph）`.raw`（param）的格式保存）
  
     其中包括编译各阶段产生的中间结果模型和最终用于片上部署的BY模型，直接被保存到:  3_deploy/modelzoo/TSN/imodel
     
      **注意**：toml中generate阶段参数不能修改，因后续plin工程中对网络中的hardop进行view操作，必须关闭MMU和ocm。

# 3. 仿真

通过配置3_deploy/modelzoo/TSN/cfg/中yaml文件的sim字段为True实现模型仿真。

```json
imodel:
   ...
   sim: true
   ...
```

# 4. 部署模型

## 部署环境检查

   * 以root账户登录片上系统terminal（ssh或串口皆可），模型库默认的模型存放路径为以下目录，如果没有请预先创建：

   ```
   /home/fmsh/ModelZoo/
   ```

   * 检查板上环境是否正确：
      1. 查看环境变量，指令：
         `icraft --version`

         看打印信息是否如下：

         ```shell
         Icraft 版本:
         * v3.7.1

         CLI 版本:
         3.7.0.0-a90988f(2412231401)
         ```
      
      2. 若是，在任意目录下输入`icraft-serve`即可打开server

      3. 检查icraft和customop安装包版本是否为`arm64`

         ```shell
         # 检查icraft安装包版本
         dpkg -l | grep icraft
         # 检查customop安装包版本
         dpkg -l | grep customop
         ```

         如果依次显示如下信息，则安装版本正确：

         ```shell
         ii  icraft                         3.7.1                             arm64        This is Icraft for arm64
         ii  customop                       3.7.1                             arm64        This is Icraft CustomOp for arm64
         ```
      
      4. 如果环境配置有误，请参考[Part 1_1 2.3.1 片上系统环境 编译环境准备](https://gitee.com/mxh-spiger/tutorial-runtime/blob/tt3.7.1/docs/Part%201_1%20quick-start.md#1%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87-2)进行部署环境配置。

      5. 根据此模型使用的硬算子，选择合适的位流，并在板上安装，所用硬算子及可选位流版本可参见本说明文档起始处的状态徽章，位流下载及安装说明请参考[1/4) 其他下载资源](https://gitee.com/mxh-spiger/icraft-introduction/tree/icraft_v3.7.1/#4%E5%85%B6%E4%BB%96%E4%B8%8B%E8%BD%BD%E8%B5%84%E6%BA%90)。

## python  runtime:

目的：在AI硬件上执行模型前向推理

1. **python运行虚拟环境要求与准备**

   - python版本：3.8（否则无法使用icraft的python API）
   - 确保已安装icraft的python安装包

     - socket模式使用：`pip install icraft-3.x.x-cp38-none-win_amd64.whl`
     - axi模式使用：`pip install icraft-3.x.x-cp38-none-manylinux2014_aarch64.whl`
   - 在选定的python运行虚拟环境中安装python运行时所需要的依赖包

     ```
     cd 3_deploy/modelzoo/TSN
     pip install -r requirements.txt
     ```
   - 安装一些便于开发pyrt的依赖包

     ```
     cd 3_deploy/Deps/modelzoo
     pip install -e .
     ```

     <div style="background-color: #FFFFCC; color: #000000; padding: 10px; border-left: 5px solid #FFA500;">
     由于python运行时代码在引入依赖包时候已经通过sys.path.append(R"../../../Deps/modelzoo")将一些便于开发pyrt的依赖包加入到了系统路径下，因此可以不用执行该步骤即可直接运行2.执行程序。这里提供额外的[pip install -e .]安装方式是为了在python运行时代码时候方便进行pyrtutils的依赖跳转。
   
2. **执行程序**

   （1）若是需要测精度，则需先下载kinetic数据集，划分好测试集后，运行以下代码进行精度测试。
   
   注意：该代码支持parse、optimize、quantize阶段仿真，以及BY阶段上板

   ```
   python ./TSN_psin_video_metric.py ../cfg/TSN_psin_test.yaml
   ```
   
   在io/output中查看结果
   
   （2）若是需要验证一段视频或测试时间，运行以下代码：
   
   ​		a) 每25帧才进行一次动作识别：
   
   ```
   python ./TSN_psin_video.py ../cfg/TSN_psin_video.yaml
   ```
   
   ​		b) 等待25帧后，每一帧和前面24帧一同均进行动作识别分类，从而实现实时动作分类：
   
   ```
   python ./TSN_psin_video_online.py ../cfg/TSN_psin_video.yaml
   ```
   
   用户可修改`TSN_psin_video.yaml`中`param`中的参数：
   
   - interval：表示间隔取帧送入TSN-net1网络，可拉大时间间隔的同时，不影响网络效率
   - num_segments： 表示将segment帧的TSN-net1的结果拼接，送入TSN-net2网络做一次动作识别。
   
   注意：因使用了PLDDR<->PLDDR搬数的优化操作，来减少TSN-net1输出与TSN-net2输入网络连接的耗时，因此`TSN_psin_video.py`和`TSN_psin_video_online.py`仅支持BY阶段上板运行。

## c++  runtime:

### PSIN工程示例

目的：编译c/c++可执行程序，在AI硬件上执行模型前向推理

模型库以ubuntu操作系统为例：

1. **编译环境准备**

   - os: ubuntu20.04
   - cmake>=3.10
   - compiler: aarch64-linux-gnu-g++/aarch64-linux-gnu-gcc
   
2. **编译c++程序**

   ```shell
   #在3.x所需的linux编译环境中
   cd 3_deploy/modelzoo/TSN/build_arm
   cmake ..
   make -j
   ```
   

   
4. **执行程序**

   ```
   cd /home/fmsh/ModelZoo/modelzoo/TSN/build_arm
   chmod 777 *
   ./TSN_psin ../cfg/TSN_psin.yaml
   ```

   在io/output中查看结果
   
   注意：CRT运行时仅提供了对抽取出的视频帧进行动作识别操作；如需测试其它动作，需先提取出视频帧，并准备好对应的txt文档，记录需要运行的视频帧顺序。

### PLIN工程示例

`TSN_plin_online.cpp`：该脚本是TSN动作识别的多线程PLIN demo。此demo将网络拆分为三部分（imk、TSN-net1、TSN-net2）多线程并行加速，且会在每一帧运行TSN-net1用于提取特征，当TSN-net1运行25帧后，会将当前帧及前面24帧的TSN-net1的输出拼接起来，用于TSN-net2网络的输入，TSN-net2会输出当前帧的动作识别结果。

**使用方法**：

​		a）首先，需要重新编译模型，包括：`TSN_25frames_plin.toml`;

​		b）修改cmakelist.txt，将第三行修改为set(TARGET_NAME TSN_plin_online)，并按照章节4.3重新编译c++程序，指令如下：

```shell
#在4.1所需的linux编译环境中
cd 3_deploy/modelzoo/TSN/build_arm
cmake ..
make -j
```

​		c）将编译生成的可执行文件拷贝到板子上，并运行以下指令执行程序：

```
cd /home/fmsh/ModelZoo/modelzoo/TSN/build_arm
chmod 777 *
./TSN_plin_online
```



# 5. 精度测试

<div style="background-color: #FFFFCC; color: #000000; padding: 10px; border-left: 5px solid #FFA500;">
由于精度测试需要遍历一个数据集中的所有图片，因此需要使用上位机作为主控操作系统（demo中是按windows作为上位机操作系统来做的），使用网口连接板子，运行时输入数据会通过上位机经由网口传到片上进行推理。
</div>

## 1. 环境准备

若已准备好环境请跳过此部分

**1. 网口调试环境准备**（如果已经准备好网口调试环境则看下一条）

1. 安装ssh
2. 查看或配置板子ip

   - 使用串口连接板子
   - `vim  /etc/rc.local`
   - 查看或设置ip

   ```
   #!/bin/bash
   ifconfig eth0 192.168.125.171 netmask 255.255.255.0
   systemctl start sshd
   ```
3. 修改本地网络适配器配置

   参考配置

   - ipv4地址：`192.168.125.2`
   - 子网掩码：`255.255.255.0`
   - 默认网关：`192.168.125.1`
   - 连接速度与双工：100mbps全双工
4. 使用网口或串口进入板上系统打开server

   上位机：

   ```cmd
   ssh root@192.168.125.171
   ```

   板上：
   确保位于root账户下，执行：

   ```shell
   icraft-serve
   ```

   * 请确保在root账户下执行上述命令
   * 设备成功打开示意图

   ```
   root@U:~# icraft-serve
   [02/22/24 02:02:00.388] [I] Using port : 9981
   [02/22/24 02:02:00.388] [I] synchronous mode
   [02/22/24 02:02:00.388] [I] [irpc::port::tcp::_waitNewConn] wait for new connection
   ```

   如果能正确运行则可以继续下一步。



## 2. 测试说明

1. **数据集准备**

* 测试数据集下载：[Kinetics-400](https://openxlab.org.cn/datasets/OpenMMLab/Kinetics-400)

* 模型测试使用Kinetic400数据集的Val部分，需先将数据集分为训练集和验证集，参考[mmaction2/tools/data/kinetics/README_zh-CN.md at main · open-mmlab/mmaction2](https://github.com/open-mmlab/mmaction2/blob/main/tools/data/kinetics/README_zh-CN.md)

  （1）在0_TSN中运行以下代码划分数据集：

  ```
  bash preprocess_k400.sh 数据集路径 保存路径   
  ```

  处理好的数据会分成train和val，保存在${DATASET_ROOT)/Kinetics-400 中，需要将测试集视频复制到  `3_deploy\modelzoo\TSN\io`中。

  （2）下载标注文件（已提供，可忽略）

  ```
  bash download_annotations.sh kinetics400
  ```

  下载好的标注文件`kinetics400_val_list_videos.txt`复制到： `3_deploy\modelzoo\TSN\io`中

* 如需测试其他数据集，需自行将视频存放于 `3_deploy\modelzoo\TSN\io`,并准备对应的GT.txt

3. **修改运行时的yaml配置文件**

   运行时需要配置一些模型路径，输入数据，后处理参数等，其配置文件在 `3_deploy/modelzoo/TSN/cfg/`

   测试时使用：`TSN_psin_test.yaml`

   需要修改：

   * imodel中参数：修改精度测试所用模型文件路径`dir`，根据所使用板子ip设置`ip`。
   * dataset中参数：更改自己的精度测试数据集路径。
   * param中参数：如果模型没有重训，则无需更改，若重训则需要修改对应部分参数。

4. **编译、执行运行时程序**

   python运行时（不需要编译）：

   ```
   cd 3_deploy/modelzoo/TSN/pyrt
   python ./TSN_psin_video_metric.py ../cfg/TSN_psin_test.yaml
   ```

   将直接输出精度指标，并记录在`TSN_metrics.log`中
   

# 6. 模型性能记录

时间测试如下：

| TSN             | input shape   | hard time |
| --------------- | ------------- | --------- |
| TSN-net-1-8bit  | [1,3,224,224] | 5.804ms   |
| TSN-net-2-8bit  | [1,25,2048]   | 0.093 ms  |
| TSN-net-1-16bit | [1,3,224,224] | 11.639ms  |
| TSN-net-2-16bit | [1,25,2048]   | 0.199 ms  |

精度测试如下：

| TSN   | qt_strategy | Top1 acc | Top5 acc | Mean acc |
| ----- | ----------- | -------- | -------- | -------- |
| float | -           | 72.78    | 90.66    | 72.77    |
| parse | -           | 69.59    | 88.47    | 69.59    |
| 8bit  | null-pc     | 68.71    | 88.19    | 68.75    |
| 16bit | null-pc     | 69.36    | 88.46    | 69.36    |

